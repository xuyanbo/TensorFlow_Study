{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow-Slim是TensorFlow中一个用于构建、训练、评估复杂模型的轻量化库。TensorFlow-Slim模块可以和TensorFlow中其他API混合使用。不过TensorFlow-Slim的这些封装使用的并不广泛。但是TensorFlow-Slim最特殊的地方是它对标准神经网络的封装，比如VGG、Inception以及ResNet，而且Google开源的训练好的图像分类模型基本都是通过TensorFlow-Slim实现的。<br/>\n",
    "## TensorFlow-Slim模块的导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow-Slim模块的优点\n",
    "Slim模块可以使模型的构建、训练、评估变得简单。<br/>\n",
    "- 允许用户使用更紧凑的代码定义模型。这是通过使用`arg_scope`、更高层级的`layers`和`variables`来实现的。这些工具增加了代码的可读性和维护性，并且简化超参的调整；<br/>\n",
    "- 提供常用的`regularizers`来简化模型开发；<br/>\n",
    "- 很多常用的计算机视觉模型(例如VGG、AlexNet)都在TensorFlow-Slim中有实现。这些模型开箱即用，并且能够以多种方式进行拓展。<br/>\n",
    "- TensorFlow-Slim使得复杂模型的拓展以及从一些现存的模型ckpt开始训练变得更加容易。<br/>\n",
    "## TensorFlow-Slim模块的组成\n",
    "TensorFlow-Slim是由几个独立的模块组成。<br/>\n",
    "- `arg_scope`：允许用户对该scope内的操作定义默认参数；<br/>\n",
    "- `data`：包含了Slim模块的dataset definition、data providers、parallel_reader及decoding utilities；<br/>\n",
    "- `evaluation`：评估模型需要的一些东西；<br/>\n",
    "- `layers`：构建模型需要的一些高级layers；<br/>\n",
    "- `learning`：训练模型需要的一些东西;<br/>\n",
    "- `losses`：常见的loss函数；<br/>\n",
    "- `metrics`：常见的评估指标；<br/>\n",
    "- `nets`：常见的深度网络(如：VGG、AlexNet)。注意：最新的TensorFlow-Slim已经没有nets了;<br/>\n",
    "- `queues`：提供一个容易、简单的开始和关闭QueueRunners的内容管理器；<br/>\n",
    "- `regulariers`：常见的权重regularizer；<br/>\n",
    "- `variables`：为变量创建和操作提供便利的封装。<br/>\n",
    "## 使用TensorFlow-Slim构建模型\n",
    "可以用TensorFlow-Slim的variables、layers和scopes来简洁地定义模型。<br/>\n",
    "### Variables\n",
    "在原生的TensorFlow中创建`Variables`需要一个预定义的值或者一个初始化机制(比如，高斯分布采样)。如果需要在指定设备上，比如GPU，创建Variable，则必须显示指定。为了简化代码的变量创建，TensorFlow-Slim在variables.py中提供了一批轻量级的函数封装，从而时定义变量更加容易。<br/>\n",
    "例如：创建一个权值变量，并且用truncated_normal初始化，用L2损失正则化，放置于CPU上。声明代码如下：<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "weights = slim.variable('weights', \n",
    "                        shape=[10,10,3,3], \n",
    "                        initializer=tf.truncated_normal_initializer(stddev=0.1), \n",
    "                        regularizer=slim.l2_regularizer(0.05), device='CPU:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在原生TensorFlow中，有两种类型的变量：regular variables(常规变量)和local(transient) variables(局部(临时)变量)。绝大多数都是常规变量，因为它们一旦创建，可以用Saver保存在磁盘上。局部变量则只在一个Session中存在，并且不会被保存在磁盘上。<br/>\n",
    "TensorFlow-Slim通过定义`model variables`可以进一步区分变量，这种变量代表一个模型的参数。model variables在学习阶段被训练或微调，在评估和预测阶段从checkpoint中加载。比如通过slim.full_connected或slim.conv2d创建的变量。`Non-model variables`是在学习或评估阶段使用，但不会在预测阶段起作用的变量。例如global_step，它在学习和评估阶段使用，但不是模型的一部分。<br/>\n",
    "通过TensorFlow-Slim可以很容易创建和获取model variables和regular variables。<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "# Model Variables\n",
    "my_weights = slim.model_variable(\"my_weights\", \n",
    "                              shape=[10, 10, 3, 3], \n",
    "                              initializer=tf.truncated_normal_initializer(stddev=0.1), \n",
    "                              regularizer=slim.l2_regularizer(0.05), device=\"/CPU:0\")\n",
    "model_variables = slim.get_model_variables()\n",
    "\n",
    "# Regular Varibales\n",
    "my_var = slim.variable(\"my_var\", \n",
    "                       shape=[20, 1], \n",
    "                       initializer=tf.zeros_initializer())\n",
    "regular_variables_and_model_variables = slim.get_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当通过TensorFlow-Slim的layer或者直接通过slim.model_variable()函数来创建model variable。TensorFlow-Slim添加变量到tf.GraphKeys.MODEL_VARIABLES集合。另外TensorFlow-Slim也提供了一个很方便的函数将模型的变量添加到集合中。<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim.add_model_variable(my_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "虽然TensorFlow的操作集合相当广泛，但神经网络的开发人员通常会在更高层次的概念上考虑模型，比如，“layers”、“losses”、“metrics”和“networks”。神经网络的层，比如卷积层、全连接层或BN层，要比一个单独的TensorFlow的操作符更加抽象，并且通常会包含若干操作符。此外，和原始操作符不同，一个层经常有一些与该层相关的可调参数变量。例如，在神经网络中，一个卷积层由许多底层操作符组成：<br/>\n",
    "- 创建权重、偏置变量；<br/>\n",
    "- 将来自上一层的数据和权值进行卷积；<br/>\n",
    "- 在卷积结果上加上偏置；<br/>\n",
    "- 应用激活函数；<br/>\n",
    "如果只用原生的TensorFlow代码，那就相当费力。<br/>\n",
    "```python\n",
    "input = ...\n",
    "with tf.name_scope('conv1_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], \n",
    "                                             dtype=tf.float32, \n",
    "                                             stddev=1e-1), \n",
    "                                             name='weight')\n",
    "    conv = tf.nn.conv2d(input, kernel, [1,1,1,1], \n",
    "                        padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[128], \n",
    "                                     dtype=tf.float32), \n",
    "                         trainable=True, name='biased')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(bias, name='scope')\n",
    "```\n",
    "为了避免代码的重复，TensorFlow-Slim提供了很多方面的神经网络layers的高层op。<br/>\n",
    "与上面等价的TensorFlow-Slim版代码：<br/>\n",
    "```python\n",
    "input = ...\n",
    "net = slim.conv2d(input, 128, [3, 3], scope='conv1_1')\n",
    "```\n",
    "对于构建神经网络的TF-Slim提供许多标准组件，包括：<br/>\n",
    "\n",
    "| Layer | TF-Slim |\n",
    "| --------   | :-----  |\n",
    "| BiasAdd | slim.bias_add |\n",
    "| BatchNorm | slim.batch_norm |\n",
    "| Conv2d | slim.conv2d |\n",
    "| Conv2dInPlane | slim.conv2d_in_plane | \n",
    "| Conv2dTranspose(Deconv) | slim.conv2d_transpose| \n",
    "| FullConnected | slim.full_connected| \n",
    "| AvgPool2D | slim.avg_pool2d| \n",
    "| Dropout | slim.dropout| \n",
    "| Flatten | slim.flatten| \n",
    "| MaxPool2D | slim.max_pool2d| \n",
    "| OneHotEncoding | slim.one_hot_encoding| \n",
    "| SeparableConv2 | slim.separable_conv2d| \n",
    "| UnitNorm | slim.unit_norm| \n",
    "\n",
    "TF-Slim还提供了两个meta-operations：repeat和stack，允许用户可以重复地使用相同的运算符。例如，VGG网络的一个片段，这个网络在两个池化层之间就有许多卷积层的堆叠：<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ...\n",
    "net = slim.conv2d(net, 256, [3,3], scope='conv3_1')\n",
    "net = slim.conv2d(net, 256, [3,3], scope='conv3_2')\n",
    "net = slim.conv2d(net, 256, [3,3], scope='conv3_3')\n",
    "net = slim.max_pool2d(net, [2,2], scope='pool2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一种减少这种代码重复的方法是使用for循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ...\n",
    "for i in range(3):\n",
    "    net = slim.conv2d(net, 256, [3,3], scope='conv3_'%(i+1))\n",
    "net = slim.max_pool2d(net, [2,2], scope='pool2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用TF-Slim的repeat操作符，代码看起来会更简洁。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = slim.repeat(net, 3, slim.conv2d, 256, [3,3], scope='conv3')\n",
    "net = slim.max_pool2d(net, [2,2], scope='pool2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slim.repeat不仅对repeated单元采用相同的参数，而且它对repeated单元的scope采用更好的命名方式(加下划线，再加迭代序号)。如上述例子中scopes将命名为conv3/conv3_1，conv3/conv3_2，conv3/conv3_3。<br/>\n",
    "TF-Slim的slim.stack允许使用不同参数来重复多个操作来构建一个多层的堆叠结构。slim.stack也为每个创建的操作符生成一个新的scope。<br/>\n",
    "下面创建MLP(Multi-Layer perceptron)的简单方式代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 冗长方式\n",
    "x = slim.fully_connected(x, 32, scope='fc/fc_1')\n",
    "x = slim.fully_connected(x, 64, scope='fc/fc_2')\n",
    "x = slim.fully_connnected(x, 128, scope='fc/fc_3')\n",
    "\n",
    "# TF-Slim方式\n",
    "x = slim.stack(x, slim.fully_connected, [32, 64, 128], scope='fc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似，可以使用stack来简化多层卷积的堆叠。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 冗长方式\n",
    "x = slim.conv2d(x, 32, [3,3], scope='core/core_1')\n",
    "x = slim.conv2d(x, 32, [1,1], scope='core/core_2')\n",
    "x = slim.conv2d(x, 64, [3,3], scope='core/core_3')\n",
    "x = slim.conv2d(x, 64, [1,1], scope='core/core_4')\n",
    "# TF-Slim stack方式\n",
    "x = slim.stack(x, slim.conv2d, [(32, [3,3]),(32,[1,1]), \n",
    "                                (64,[3,3]),(64,[1,1])],\n",
    "               scope='core')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scopes\n",
    "除了TensorFlow中的name_scope、variable_scope的几种scope机制，slim增加一个名为arg_scope的新scope机制。这个新scope允许用户给arg_scope里的一个或多个op指定默认参数。<br/>\n",
    "举例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-Slim原始方式\n",
    "net = slim.conv2d(inputs, 64, [11,11], 4, padding='SAME', \n",
    "                  weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                  weights_regularizer=slim.l2_regularizer(0.0005), scope='conv1')\n",
    "net = slim.conv2d(net, 128, [11,11], padding='VALID',\n",
    "                  weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                  weights_regularizer=slim.l2_regularizer(0.0005), scope='conv2')\n",
    "net = slim.conv2d(net, 256, [11,11], padding='SAME', \n",
    "                  weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                  weights_regularizer=slim.l2_regularizer(0.0005), scope='conv3')\n",
    "# TF-Slim的arg_scope方式\n",
    "with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                   activation_fn = tf.nn.relu,\n",
    "                   weights_initalizer=tf.truncated_normal_initializer(stddv=0.01),\n",
    "                   weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "    with slim.arg_scope([slim.conv2d], stride=1, padding='SAME'):\n",
    "        net = slim.conv2d(inputs, 64, [11,11], 4, \n",
    "                          padding='VALID',scope='conv1')\n",
    "        net = slim.conv2d(net, 256, [5, 5], \n",
    "                         weights_initializer=tf.truncated_normal_initializer(stddev=0.03),\n",
    "                         scope='conv2')\n",
    "        net = slim.fully_connected(net, 1000, activation_fn=None, \n",
    "                                   scope='fc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个`arg_scope`中对`conv2d`、`fully_connected`层使用相同的`weights_initializer`。在第二`arg_scope`中，给`conv2d`的其他默认参数指定。\n",
    "## Training Models\n",
    "模型的训练需要model、loss function、gradient computation和training routine。TF-Slim提供了常见的loss函数、一系列训练和评估需要的函数。<br/>\n",
    "### Losses\n",
    "根据官方提示，`slim.losses`模块将被移除，请使用`tf.losses`模块，两者功能完全一致。<br/>\n",
    "TF-Slim通过`losses`模块提供了一种易用的机制去定义和跟踪损失函数的足迹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = slim.losses.softmax_cross_entropy(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于多目标模型的情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_loss = slim.losses.softmax_cross_entropy(scene_predictions,\n",
    "                                                       scene_labels)\n",
    "sum_of_squares_loss = slim.losses.sum_of_squares(depth_predictions,\n",
    "                                                depth_labels)\n",
    "# 以下两行代码等价\n",
    "total_loss = classification_loss + sum_of_squares_loss\n",
    "total_loss = slim.losses.get_total_loss(add_regularization_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`slim.losses.get_total_loss()`的工作原理：当用TF-Slim创建一个loss函数时，TF-Slim会把loss添加到一个特定容器中。这使得我们既可以手动管理loss，也可以使用TF-Slim来管理loss。<br/>\n",
    "在自定义loss函数的情况下，使用TF-Slim来管理losses。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "classification_loss = slim.losses.softmax_cross_entropy(scene_predictions,\n",
    "                                                       scene_labels)\n",
    "sum_of_squares_loss = slim.losses.sum_of_squares(depth_predictions,\n",
    "                                                depth_labels)\n",
    "pose_loss = MyCustomLossFunction(pose_predictions, pose_labels)\n",
    "# 将自定义损失函数加入集合中\n",
    "slim.losses.add_loss(pose_loss)\n",
    "# 正则化损失\n",
    "regularization_loss = tf.add_n(slim.losses.get_regularization_losses())\n",
    "# 以下两行代码是等价的\n",
    "total_loss = classification_loss + sum_of_squares_loss + \n",
    "             pose_loss + regularization_loss\n",
    "total_loss = slim.losses.get_total_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个例子中，我们既可以手动产生这个总的loss，也可以让TF-Slim知晓这个自定义函数，然后托管给TF-Slim。<br/>\n",
    "### Training Loop\n",
    "在learning.py中，TF-Slim提供了简单却非常强大的训练模型的工具集。包括Train函数、重复衡量损失、计算梯度以及保存模型到磁盘中，另外还有 一些方便操作梯度的函数。例如,当我们定义好了模型、损失函数以及优化方式，就可以调用`slim.learning.create_train_op`和`slim.learning.train`去执行优化。<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "# 建立模型和指定损失函数\n",
    "...\n",
    "total_loss = slim.losses.get_total_loss()\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "# 计算loss\n",
    "# 进行梯度更新\n",
    "train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "# 模型保存路径\n",
    "logdir = ...\n",
    "# 只执行1000步梯度下降\n",
    "# 每个5分钟计算一次summaries\n",
    "# 每个10分钟保存一次模型\n",
    "slim.learning.train(train_op, \n",
    "                    logdir, \n",
    "                    number_of_steps=1000, \n",
    "                    save_summaries_secs=300, \n",
    "                    save_interval_secs=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Existing Models\n",
    "### 从ckpt中恢复变量\n",
    "在一个模型训练结束后，可以使用`tf.train.Saver()`从一个给定checkpoint中恢复`Variables`。在很多情况下，`tf.train.Saver()`提供了一个简单的恢复所有或一小部分变量的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "v1 = tf.Variable(tf.constant(1.0), name=\"v1\")\n",
    "v2 = tf.Variable(tf.constant(0.0), name=\"v2\")\n",
    "\n",
    "restorer = tf.train.Saver()\n",
    "restorer = tf.train.Saver([v1,v2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    restorer.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 部分恢复模型\n",
    "很多时候，想在新数据集或一个新的任务上微调(fine-tune)一个已经训练好的模型。在这些情况下，能够使用Slim的辅助函数去选择一部分的变量来进行恢复："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = slim.variable(name='v1', ...)\n",
    "v2 = slim.variable(name='nested/v2', ...)\n",
    "\n",
    "variables_to_restore = slim.get_variables_by_name('v2')\n",
    "variables_to_restore = slim.get_variables_by_suffix(2)\n",
    "variables_to_restore = slim.get_variables(scope='nested')\n",
    "variables_to_restore = slim.get_variables_to_restore(inclue=['nested'])\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude=['v1'])\n",
    "\n",
    "restorer = tf.train.Saver(variables_to_restore)\n",
    "with tf.Session() as sess:\n",
    "    restorer.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不同变量名称的模型的恢复\n",
    "当从一个checkpoint中恢复variables时，`Saver`会在checkpoint中寻找变量的名字，并将它们映射到当前图中的variables。在创建一个Saver时，指定要恢复的Variable，TF-Slim会自动调用`var.op.name`来获得variables的名字，然后进行映射。<br/>\n",
    "当checkpoint中变量名和当前计算图中的变量名不同时，需要提供一个字典，这个字典将checkpoint中的变量名映射到计算图中的变量。<br/>\n",
    "举例如下<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_in_checkpoint(var):\n",
    "    return 'vgg16/' + var.op.name\n",
    "\n",
    "def name_in_checkpoint(var):\n",
    "    if \"weights\" in var.op.name:\n",
    "        return var.op.name.replace(\"weights\", \"params1\")\n",
    "    if \"bias\" in var.op.name:\n",
    "        return var.op.name.replace(\"bias\", \"params2\")\n",
    "variables_to_restore = slim.get_model_variables()\n",
    "variables_to_restore = {name_in_checkpoint(var):var for var \n",
    "                        in variables_to_restore}\n",
    "restorer = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    restorer.restore(sess, \"/tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在一个不同的任务上微调模型\n",
    "有预训练好的VGG16模型，这个模型是在1000类的ImageNet数据集上训练的。但是，我们想要将它应用到只有20类的Pascal VOC数据集上。因此使用预训练好的模型的参数来初始化我们的新模型，除了最后一层。<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载Pascal VOC数据\n",
    "image, label = MyPascalVocDataLoader(...)\n",
    "images, labels = tf.train.batch([image, label], batch_size=32)\n",
    "\n",
    "# 建立模型\n",
    "predictions = vgg.vgg_16(images)\n",
    "train_op = slim.learning.create_train_op(...)\n",
    "\n",
    "# 指定预训练模型保存路径\n",
    "model_path = '/path/to/pre_trained_on_imagenet.checkpoint'\n",
    "# 指定新模型路径\n",
    "log_dir = '/path/to/my_pascal_model/dir/'\n",
    "\n",
    "# 卷积层恢复\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude=[\n",
    "    'fc6', 'fc7', 'fc8'])\n",
    "init_fn = slim.assign_from_checkpoint_fn(model_path, variables_to_restore)\n",
    "# 开始训练\n",
    "slim.learning.train(train_op, log_dir, init_fn=init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Models\n",
    "通过选择一组评价指标(evaluation metrics)来对一个已训练好的模型性能进行评估，评估代码一般会加载数据，执行前向传播，然后将结果与真实值进行比较并记录评估分数。这个步骤可能执行一次，也可能周期性地执行。<br/>\n",
    "### Metrics\n",
    "定义了一个评价指标来衡量模型的性能，这个评价指标对于模型的评估十分重要。TF-Slim提供了很多评价指标操作，这些op使得模型的评估变得容易。理论上，计算评价指标的值能够被分为三部分：\n",
    "1. 初始化(Initialization)：初始化评价指标相关的一些变量。\n",
    "2. 聚合(Aggregation)：执行用于计算指标的运算流程。\n",
    "3. 收尾：执行其他用于计算指标值的操作。(可选)\n",
    "下面举例metrics的API的使用方法：<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = LoadTestData(...)\n",
    "predictions = MyModel(images)\n",
    "\n",
    "mae_value_op, mae_update_op = slim.metrics.streaming_mean_absolute_error(\n",
    "    predictions, labels)\n",
    "mre_value_op, mre_update_op = slim.metrics.streaming_mean_relative_error(\n",
    "    predictions, labels)\n",
    "pl_value_op, pl_update_op = slim.metrics.percentage_less(\n",
    "    mean_relavtive_errors, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个metric会返回两个值，分别是value_op和update_op。value_op表示和当前指标值幂等的操作。update_op是上文提到的执行聚合步骤并返回指标值的操作符。<br/>\n",
    "跟踪每个value_op和update_op是非常费劲的。为了解决这个问题，TF-Slim提供了两个方便的函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将value和update的op聚合到两个list里\n",
    "value_ops, update_ops = slim.metrics.aggregate_metrics(\n",
    "    slim.metrics.streaming_mean_absolute_error(predictions, labels), \n",
    "    slim.metrics.streaming_mean_squared_error(predictions, labels))\n",
    "# 将value和update的op聚合到两个字典里\n",
    "names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\n",
    "    \"eval/mean_absolute_error\": slim.metrics.streaming_mean_absolute_error(predictions, labels), \n",
    "    \"eval/mean_squared_error\": slim.metrics.streaming_mean_squared_error(predictions, labels)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Loop\n",
    "TF-Slim提供了一个评估模块(evaluation.py)，这个模块包含了编写模型评估脚本的辅助函数。这些函数包括可周期运行评估、批量数据之间的评估指标、打印并总结指标结果函数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
